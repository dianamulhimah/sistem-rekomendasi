# -*- coding: utf-8 -*-
"""Proyek Akhir : Membuat Model Sistem Rekomendasi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zYDzZvZ1UmQwKrj_Xxr2cy4USm8OqHyZ

# **Laporan Proyek Machine Learning - Diana Mulhimah**

## **Book Recommendation Dataset**

## **Project Overview**
Seiring dengan berkembangnya teknologi informasi dan meningkatnya kebutuhan akan akses informasi yang cepat dan relevan, sistem rekomendasi memainkan peran penting dalam membantu pengguna menavigasi volume data yang sangat besar. Dalam konteks perpustakaan maupun aplikasi digital berbasis literasi, pengguna sering mengalami kesulitan dalam menemukan buku yang sesuai dengan preferensi mereka. Hal ini disebabkan oleh berbagai faktor, seperti keterbatasan waktu, minimnya informasi, serta banyaknya pilihan yang tersedia.
Untuk mengatasi permasalahan tersebut, sistem rekomendasi buku hadir sebagai solusi yang cerdas dengan tujuan menyederhanakan proses pencarian informasi dan meningkatkan pengalaman pengguna. Sistem ini bekerja dengan menganalisis perilaku pengguna, preferensi individu, serta karakteristik konten buku untuk memberikan rekomendasi yang relevan dan personal.
Salah satu pendekatan utama yang digunakan dalam sistem rekomendasi adalah Collaborative Filtering (CF), yang memanfaatkan interaksi dan penilaian dari banyak pengguna untuk menyarankan item yang disukai oleh pengguna dengan pola preferensi serupa. Metode ini terbagi menjadi dua, yaitu user-based dan item-based. CF terbukti efektif terutama saat tersedia data interaksi pengguna yang cukup banyak dan konsisten. Sebagai contoh, [^1] menerapkan algoritma Singular Value Decomposition (SVD) dalam CF, yang berhasil mereduksi sparsity dan meningkatkan kualitas prediksi rekomendasi buku.
Di sisi lain, pendekatan Content-Based Filtering (CBF) juga banyak digunakan, terutama dalam konteks perpustakaan. CBF bekerja dengan menganalisis atribut atau fitur dari item seperti judul, pengarang, dan genre untuk merekomendasikan item serupa. Penelitian oleh [^2] dan [^3] menunjukkan bahwa pendekatan ini dapat menghasilkan rekomendasi yang akurat berdasarkan deskripsi konten meskipun tanpa melibatkan data dari pengguna lain.
Proyek ini bertujuan untuk mengembangkan sistem rekomendasi buku dengan mengombinasikan pendekatan Collaborative Filtering dan Content-Based Filtering, berdasarkan efektivitas yang telah dibuktikan oleh beberapa studi sebelumnya. Dengan adanya sistem rekomendasi ini, diharapkan pengguna dapat memperoleh saran buku yang lebih personal dan relevan dengan preferensi mereka, serta mendukung digitalisasi layanan literasi yang efisien dan adaptif terhadap kebutuhan pengguna.

## **Business Understanding**
Pada tahap ini, dilakukan proses klarifikasi terhadap permasalahan yang dihadapi pengguna dalam menemukan buku yang relevan dengan preferensi mereka. Banyak pengguna kesulitan menemukan buku serupa setelah menyukai suatu buku karena keterbatasan informasi atau banyaknya pilihan yang tersedia. Selain itu, pengguna juga sering melewatkan buku-buku potensial yang belum pernah mereka baca karena tidak muncul dalam pencarian atau rekomendasi.

### Problem Statements
*	Bagaimana sistem dapat merekomendasikan buku yang mirip dengan buku yang disukai oleh pengguna berdasarkan kontennya?
* Bagaimana sistem dapat memberikan rekomendasi buku yang belum pernah dibaca oleh pengguna tetapi mungkin disukai, berdasarkan perilaku pengguna lain?

### Goals
* Menghasilkan rekomendasi buku berdasarkan fitur konten buku seperti judul dan penulis, sehingga pengguna mendapatkan saran buku yang mirip dengan preferensinya sebelumnya menggunakan pendekatan Content-Based filtering.
* Memberikan rekomendasi buku yang belum dibaca oleh pengguna namun disukai oleh pengguna lain dengan pola rating serupa, menggunakan pendekatan Collaborative Filtering.

### Solution statements
* Solution 1: Content-Based Filtering (CBF) Menganalisis metadata buku untuk merekomendasikan buku serupa dengan yang telah disukai atau dibaca oleh pengguna. Teknik yang digunakan yaitu TF-IDF vectorization dan Cosine similarity.
* Solution 2: Collaborative Filtering (CF) – Menganalisis interaksi pengguna terhadap buku (dalam bentuk data rating), dan menemukan pola kesamaan antar pengguna untuk merekomendasikan buku yang belum pernah dinilai oleh pengguna tersebut. Teknik yang digunakan evaluasi dengan metrik RMSE.

# **Data Understanding**
Pada proyek ini, kita menggunakan **Book Recommendation Dataset** yang tersedia secara publik melalui situs  yang bersumber dari [Kaggle](https://https://www.kaggle.com/). Dataset ini berisi informasi tentang buku, pengguna, serta rating yang diberikan oleh pengguna terhadap buku-buku tersebut. Dataset ini sering digunakan dalam tugas sistem rekomendasi karena kompleksitas dan keragaman datanya.
Link Dataset: [Kaggle - Book Recommendation Dataset](https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset)

Dataset ini terdiri dari 3 file utama, yaitu:
1. `Books.csv` — Informasi metadata buku.
2. `Users.csv` — Informasi pengguna.
3. `Ratings.csv` — Nilai rating yang diberikan pengguna terhadap buku.

**Deskripsi Variabel**
<br/>**Books.csv**
Berisi metadata dari setiap buku:
* `ISBN`: Nomor unik untuk identifikasi buku.
* `Book-Title`: Judul buku.
* `Book-Author`: Nama penulis.
* `Year-Of-Publication`: Tahun terbit buku.
* `Publisher`: Nama penerbit buku.
* `Image-URL-S`: Tautan ke gambar sampul buku dalam ukuran kecil.
* `Image-URL-M`: Tautan ke gambar sampul buku dalam ukuran sedang.
* `Image-URL-L`: Tautan ke gambar sampul buku dalam ukuran besar.

**Users.csv**
Berisi informasi pengguna yang memberi rating:
* `User-ID`: ID unik pengguna.
* `Location`: Lokasi pengguna (format: kota, negara bagian, negara).
* `Age`: Umur pengguna (dapat berisi nilai kosong atau tidak valid).

**Ratings.csv**
Berisi informasi rating yang diberikan oleh pengguna terhadap buku:
* `User-ID`: ID pengguna yang memberi rating.
* `ISBN`: ISBN buku yang dinilai.
* `Book-Rating`: Rating yang diberikan, dalam skala 0–10
"""

https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset
https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset?select=Users.csv
https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset?select=Books.csv
https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset?select=Ratings.csv

"""# **Import Liblary**"""

# Import library
import os
import kagglehub
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

"""# **Load Dataset**

Di tahap ini memuat dataset
"""

# Mengguunakan path yang disediakan oleh kagglehub untuk menemukan dataset
arashnic_book_recommendation_datase_path = kagglehub.dataset_download('arashnic/book-recommendation-dataset')

# Buat path lengkap ke setiap file CSV
users_csv_path = os.path.join(arashnic_book_recommendation_datase_path, 'Users.csv')
books_csv_path = os.path.join(arashnic_book_recommendation_datase_path, 'Books.csv')
ratings_csv_path = os.path.join(arashnic_book_recommendation_datase_path, 'Ratings.csv')

print('Data source import complete.')

# Baca dataset menggunakan path untuk setiap file
users = pd.read_csv(users_csv_path)
books = pd.read_csv(books_csv_path, low_memory=False)
ratings = pd.read_csv(ratings_csv_path)

print('Jumlah ID unik pengguna: ', len(users['User-ID'].unique()))
print('Jumlah buku unik: ', len(books['ISBN'].unique()))
print('Jumlah rating: ', len(ratings))

"""# **Univariate Exploratory Data Analysis**

Melakukan eksplorasi awal untuk memahami struktur data, melihat distribusi data, dll.
"""

users.info()

users.head()

print('Banyak data: ', len(users['User-ID'].unique()))
print('Umur Pengguna: ', users['Age'].unique())
print('Lokasi Pengguna: ', users['Location'].unique())

print('Banyak data Usia: ', len(users['Age'].unique()))
print('Lokasi Pengguna: ', users['Location'].unique())

# Plot distribusi usia
plt.figure(figsize=(10, 6))
users['Age'].dropna().astype(int).clip(0, 100).hist(bins=30, color='skyblue', edgecolor='black')
plt.title('Distribusi Usia Pengguna')
plt.xlabel('Usia')
plt.ylabel('Jumlah Pengguna')
plt.grid(False)
plt.show()

books.info()

books.head()

print('Jumlah Tahun terbit buku: ', len(books['Year-Of-Publication'].unique()))
print('Penulis buku: ', books['Book-Author'].unique())

print('Banyak Judul Buku: ', len(books['Book-Title'].unique()))
print('Judul Buku: ', books['Book-Title'].unique())

books['Year-Of-Publication'] = pd.to_numeric(books['Year-Of-Publication'], errors='coerce')

plt.figure(figsize=(12, 6))
books['Year-Of-Publication'].dropna().astype(int).clip(1900, 2022).hist(bins=50, color='orange', edgecolor='black')
plt.title('Distribusi Tahun Publikasi Buku')
plt.xlabel('Tahun Publikasi')
plt.ylabel('Jumlah Buku')
plt.grid(False)
plt.show()

ratings.info()

ratings.head()

print('Jumlah UserID: ', len(ratings['User-ID'].unique()))
print('Jumlah ISBN: ', len(ratings['ISBN'].unique()))
print('Jumlah Rating: ', len(ratings['Book-Rating'].unique()))
print('Jumlah data rating: ', len(ratings))

plt.figure(figsize=(8,5))
sns.countplot(data=ratings, x='Book-Rating', hue='Book-Rating', palette='Set2', legend=False)
plt.title('Distribusi Rating Buku')
plt.xlabel('Rating')
plt.ylabel('Jumlah')
plt.show()

"""# **Data Preprocessing**"""

books = books.drop(columns=['Image-URL-S', 'Image-URL-M', 'Image-URL-L'])
books

# Pilih 10000 user unik secara acak
sample_users = users['User-ID'].dropna().unique()
sample_users = pd.Series(sample_users).sample(n=10000, random_state=42).values

# Filter ratings hanya untuk 10000 user terpilih
ratings_sample = ratings[ratings['User-ID'].isin(sample_users)]

# Pilih 10000 buku dari rating user yang sudah di-filter
sample_books = ratings_sample['ISBN'].dropna().unique()
sample_books = pd.Series(sample_books).sample(n=10000, random_state=42).values

# Filter rating hanya untuk buku terpilih
ratings_sample = ratings_sample[ratings_sample['ISBN'].isin(sample_books)]

# Batasi rating menjadi 10000 baris acak (jika lebih dari 5000)
if len(ratings_sample) > 10000:
    ratings_sample = ratings_sample.sample(n=10000, random_state=42)

# Filter buku sesuai buku yang dipilih dari ratings_sample (mengantisipasi filtering)
books_sample = books[books['ISBN'].isin(ratings_sample['ISBN'])]

# Filter users sesuai user yang ada di ratings_sample
users_sample = users[users['User-ID'].isin(ratings_sample['User-ID'])]

ratings_sample.isnull().sum()

ratings_sample.groupby('ISBN').sum()

all_ratings = ratings_sample
all_ratings

all_books = pd.merge(all_ratings, books[['ISBN','Book-Title','Book-Author']], on='ISBN', how='left')
all_books

"""# **Data Preparation**

Tahap ini bertujuan untuk menyiapkan data agar dapat digunakan dalam membangun sistem rekomendasi, baik untuk pendekatan Content-Based Filtering maupun Collaborative Filtering. Teknik data preparation dilakukan secara sistematis untuk membersihkan, menyaring, dan memformat data ke dalam struktur yang sesuai untuk pemodelan.
"""

all_books.isnull().sum()

# Membersihkan missing value dengan fungsi dropna()
all_books_clean = all_books.dropna()
all_books_clean

all_books_clean.isnull().sum()

preparation = all_books_clean
preparation.sort_values('ISBN')

# Membuang data duplikat pada variabel preparation
preparation = preparation.drop_duplicates('ISBN')
preparation

"""## **Data Preparation algoritma Content-based Filtering**"""

# Mengonversi data series 'ISBN' menjadi dalam bentuk list
book_id = preparation['ISBN'].tolist()

# Mengonversi data series 'Book-Author' menjadi dalam bentuk list
book_author = preparation['Book-Author'].tolist()

# Mengonversi data series 'Book-Title' menjadi dalam bentuk list
book_title = preparation['Book-Title'].tolist()

print(len(book_id))
print(len(book_author))
print(len(book_title))

# Membuat dictionary untuk data ‘book_id’, ‘book_author’, dan ‘book_title’
book_new = pd.DataFrame({
    'id': book_id,
    'book_author': book_author,
    'book_title': book_title
})
book_new

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Melakukan perhitungan idf pada data book_title
tf.fit(book_new['book_title'])

# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names_out()

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(book_new['book_title'])

# Melihat ukuran matrix tfidf
tfidf_matrix.shape

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

# Membuat dataframe untuk melihat tf-idf matrix

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=book_new.book_author
).sample(8842, axis=1).sample(10, axis=0)

"""## **Data Preparation algoritma Collaborative Filtering**

Collaborative Filtering didasarkan pada interaksi pengguna terhadap item. Sistem merekomendasikan buku yang disukai oleh pengguna lain yang memiliki preferensi serupa.
"""

# Membaca dataset

df = ratings_sample
df

# Mengubah User-ID menjadi list tanpa nilai yang sama
user_ids = df['User-ID'].unique().tolist()
print('list User-ID: ', user_ids)

# Melakukan encoding User-ID
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded User-ID : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke User-ID
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke User-ID: ', user_encoded_to_user)

# Mengubah ISBN menjadi list tanpa nilai yang sama
book_ids = df['ISBN'].unique().tolist()

# Melakukan proses encoding ISBN
book_to_book_encoded = {x: i for i, x in enumerate(book_ids)}

# Melakukan proses encoding angka ke ISBN
book_encoded_to_book = {i: x for i, x in enumerate(book_ids)}

# Mapping User-ID ke dataframe user
df['user'] = df['User-ID'].map(user_to_user_encoded)

# Mapping ISBN ke dataframe book
df['book'] = df['ISBN'].map(book_to_book_encoded)

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)

# Mendapatkan jumlah book
num_book = len(book_encoded_to_book)
print(num_book)

# Mengubah rating menjadi nilai float
df['Book-Rating'] = df['Book-Rating'].values.astype(np.float32)

# Nilai minimum rating
min_rating = min(df['Book-Rating'])

# Nilai maksimal rating
max_rating = max(df['Book-Rating'])

print('Number of User: {}, Number of Book: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_book, min_rating, max_rating
))

# Mengacak dataset
df = df.sample(frac=1, random_state=42)
df

# Membuat variabel x untuk mencocokkan data user dan book menjadi satu value
x = df[['user', 'book']].values

# Membuat variabel y untuk membuat rating dari hasil
y = df['Book-Rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""# **Modeling**

Sistem rekomendasi dalam proyek ini dikembangkan menggunakan dua pendekatan utama, yaitu Content-Based Filtering (CBF) dan Collaborative Filtering (CF). Tujuan dari model ini adalah untuk membantu pengguna menemukan buku yang sesuai dengan preferensi mereka—baik berdasarkan kemiripan konten maupun perilaku pengguna lain.

## **Model Development dengan Content Based Filtering**
"""

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama book_author
cosine_sim_df = pd.DataFrame(cosine_sim, index=book_new['book_author'], columns=book_new['book_author'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap book
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

def book_recommendations(nama_author, similarity_data=cosine_sim_df, items=book_new[['book_author', 'book_title']], k=5):

    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,nama_author].to_numpy().argpartition(
        range(-1, -k, -1))

    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Drop nama_author agar nama buku yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(nama_author, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

book_new[book_new.book_author.eq('Thomas Robbins')]

# Mendapatkan rekomendasi buku yang mirip dengan
book_recommendations('Thomas Robbins')

"""## **Model Development dengan Collaborative Filtering**"""

import tensorflow as tf
from tensorflow import keras

class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_book, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_book = num_book
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.book_embedding = layers.Embedding( # layer embeddings book
        num_book,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.book_bias = layers.Embedding(num_book, 1) # layer embedding book bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    book_vector = self.book_embedding(inputs[:, 1]) # memanggil layer embedding 3
    book_bias = self.book_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_book = tf.tensordot(user_vector, book_vector, 2)

    x = dot_user_book + user_bias + book_bias

    return tf.nn.sigmoid(x) # activation sigmoid

model = RecommenderNet(num_users, num_book, 50) # inisialisasi model

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

# Memulai training

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 100,
    validation_data = (x_val, y_val)
)

book_df = book_new
df = ratings_sample

# Mengambil sample user
user_id = df['User-ID'].sample(1).iloc[0]
book_visited_by_user = df[df['User-ID'] == user_id]

# Operator bitwise (~), bisa diketahui di sini https://docs.python.org/3/reference/expressions.html
book_not_visited = book_new[~book_new['id'].isin(book_visited_by_user.ISBN.values)]['id']
book_not_visited = list(
    set(book_not_visited)
    .intersection(set(book_to_book_encoded.keys()))
)

book_not_visited = [[book_to_book_encoded.get(x)] for x in book_not_visited]
user_encoder = user_to_user_encoded.get(user_id)
user_book_array = np.hstack(
    ([[user_encoder]] * len(book_not_visited), book_not_visited)
)

ratings = model.predict(user_book_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_book_ids = [
    book_encoded_to_book.get(book_not_visited[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('Book with high ratings from user')
print('----' * 8)

top_book_user = (
    book_visited_by_user.sort_values(
        by = 'Book-Rating',
        ascending=False
    )
    .head(5)
    .ISBN.values
)

book_df_rows = book_df[book_df['id'].isin(top_book_user)]
for row in book_df_rows.itertuples():
    print(row.book_author, ':', row.book_title)

print('----' * 8)
print('Top 10 book recommendation')
print('----' * 8)

recommended_book = book_df[book_df['id'].isin(recommended_book_ids)]
for row in recommended_book.itertuples():
    print(row.book_author, ':', row.book_title)

"""# **Evaluasi**

Tahap evaluasi bertujuan untuk mengukur seberapa baik sistem rekomendasi yang dibangun dalam memberikan rekomendasi yang relevan kepada pengguna.

## **Content-Based Filtering -> Precision**

Dalam proyek ini, evaluasi difokuskan pada **Content-Based Filtering (CBF)** dengan menggunakan metrik **Precision\@K**.
"""

# Top-5 hasil rekomendasi dari fungsi Content-Based
recommended = book_recommendations('Thomas Robbins')

# Daftar penulis atau judul yang dianggap relevan
relevant_authors = ['Elmore Leonard']
relevant_titles = ['Bandits', 'Tishomingo Blues', 'Out of Sight', 'Cuba Libre', 'Gold Coast']

# Cek relevansi
recommended['is_relevant'] = recommended.apply(
    lambda x: (x['book_author'] in relevant_authors) or (x['book_title'] in relevant_titles),
    axis=1
)

# Hitung Precision@
total_recs = len(recommended)
relevant_recs = recommended['is_relevant'].sum()
precision = relevant_recs / total_recs if total_recs > 0 else 0

print(f"Precision@: {precision:.2f}")

"""## **Collaborative Filtering -> Metrik Root Mean Squared Error (RMSE)**

Dalam proyek ini, evaluasi pada **Collaborative Filtering (CF)** dengan menggunakan metrik **Root Mean Squared Error (RMSE)**.
"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

final_rmse_train = history.history['root_mean_squared_error'][-1]
final_rmse_val = history.history['val_root_mean_squared_error'][-1]

print(f"Final RMSE (Train): {final_rmse_train:.4f}")
print(f"Final RMSE (Validation): {final_rmse_val:.4f}")